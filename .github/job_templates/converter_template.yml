parameters:
  name: ''
  pool: ''
  customMatrixes: ''  


jobs:
- job: ${{ parameters.name }}
  timeoutInMinutes: 9000
  cancelTimeoutInMinutes: 200
  pool: 
    name: ${{ parameters.pool }}
  strategy:
    matrix:
      ${{ insert }}: ${{parameters.customMatrixes}}
  
  steps:

  - bash: |
      nvidia-smi
    displayName: "dump nvidia-smi"
    condition: startsWith(variables['DEVICE_TYPE'], 'cu')

  - script: |
      docker run --gpus all --rm \
          --ipc=host \
          --volume $(Build.SourcesDirectory):/ort_src \
          --volume $(Build.BinariesDirectory):/build \
          -e CCACHE_DIR=/cache -w /ort_src \
          -e HF_TOKEN=$(hf_token) \
          -e MODEL_NAME=$(MODEL_NAME) \
          -e DEVICE_TYPE=$(DEVICE_TYPE) \
          -e DATA_TYPE=$(DATA_TYPE) \
          ptebic.azurecr.io/public/aifx/acpt/stable-ubuntu2004-cu121-py310-torch222:biweekly.202410.2 /bin/bash converter/convert_to_onnx.sh
    env:
      hf_token: $(hf_token)
      MODEL_NAME: $(MODEL_NAME)
      DEVICE_TYPE: $(DEVICE_TYPE)
      DATA_TYPE: $(DATA_TYPE)
    workingDirectory: $(Build.SourcesDirectory)
    displayName: "Export Onnx model by turnkey"

  - task: AzureCLI@2
    displayName: 'upload model to Blob Storage'
    inputs:
      azureSubscription: AIInfraBuild
      scriptLocation: inlineScript
      scriptType: bash
      inlineScript: |
        cd $(Build.BinariesDirectory)
        azcopy copy './oga_models' 'https://sunghchostorageaccount.blob.core.windows.net/model_publish/$(MODEL_NAME)' --recursive