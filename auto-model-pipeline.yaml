
parameters:
 - name: model_name
   displayName: mode name on huggingface website
   type: string
   default: meta-llama/Llama-3.2-3B-Instruct
 - name: download_from_blob
   displayName: download model from azure blob
   type: string
   default: false
 - name: run_baseline_model
   displayName: run baseline model or not
   type: string
   default: true
 - name: convert_onnx_model
   displayName: convert onnx model or not
   type: string
   default: true 
 - name: run_onnx_model
   displayName: run onnx model or not
   type: string
   default: true

pool: Onnxruntime-Linux-GPU-A100-WUS3
jobs:
- job: Test
  timeoutInMinutes: 480
  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.12'
      architecture: 'x64'

  - bash: |
      nvidia-smi
    displayName: "dump nvidia-smi"


  - script: |
      azcopy copy "https://sunghchostorageaccount.blob.core.windows.net/phi-3/phi-4-mini-instruct-01072025" --recursive $(Build.BinariesDirectory)
      pwd
    workingDirectory: $(Build.SourcesDirectory)
    displayName: "Download model from azure blob"

    condition: eq(${{ parameters.download_from_blob }}, 'true')
  - bash: |
      echo "Processing checkpoint"

      checkpoint="${{ parameters.model_name }}"

      
      formatted_checkpoint=$(echo "$checkpoint" | tr '/' '_' | tr '[:upper:]' '[:lower:]')
      formatted_name=$(echo "$formatted_checkpoint" | tr '.' '_' | tr '[:upper:]' '[:lower:]')


      echo "##vso[task.setvariable variable=formatted_checkpoint]$formatted_checkpoint"
      echo "##vso[task.setvariable variable=formatted_name]$formatted_name"
      echo "Formatted checkpoint: $formatted_checkpoint"
      echo "Formatted name: $formatted_name"
    displayName: "Process checkpoint"

  - script: |
      docker run --gpus all --rm \
          --ipc=host \
          --volume $(Build.SourcesDirectory):/ort_src \
          --volume $(Build.BinariesDirectory):/build \
          -e CCACHE_DIR=/cache -w /ort_src \
          -e HF_TOKEN=$(hf_token) \
          -e MODEL_NAME=${{ parameters.model_name }} \
          ptebic.azurecr.io/public/aifx/acpt/stable-ubuntu2004-cu121-py310-torch222:biweekly.202410.2 /bin/bash /ort_src/docker_export_model_script.sh
    workingDirectory: $(Build.SourcesDirectory)
    displayName: "Export Onnx model by turnkey"
    condition: eq(${{ parameters.convert_onnx_model }}, 'true')


  - script: |
      # search for "genai_config.json" under folder "$(Build.BinariesDirectory)/oga_models/"
      model_config_folder=`find $(Build.BinariesDirectory)/oga_models/ -name genai_config.json -printf "%h\n"`
      

      # verify only one config is found
      num_models=`echo -n "$model_config_folder" | grep -c '^'`
      if [[ $num_models -ne 1 ]]; then
        echo "The output model folder should contains exactly one genai_config.json file, but found $num_models"
        exit 1
      fi

      echo "model folder: $model_config_folder"
      
      docker run --gpus all --rm \
          --ipc=host \
          --volume $(Build.SourcesDirectory):/ort_src \
          --volume $(Build.BinariesDirectory):/build \
          --volume $model_config_folder:/model \
          -p 8000:8000 \
          -e CCACHE_DIR=/cache -w /ort_src \
          ptebic.azurecr.io/public/aifx/acpt/stable-ubuntu2004-cu121-py310-torch222:biweekly.202410.2 /bin/bash /ort_src/docker_script.sh
    workingDirectory: $(Build.SourcesDirectory)
    displayName: "start onnx model endpoint and RAI eval in container"
    condition: eq(${{ parameters.run_onnx_model }}, 'true')

  # TODO: rui-ren baseline model from azure blob.
  - script: |
      baseline_model_folder=`find $(Build.BinariesDirectory)/oga_models/ -name config.json -printf "%h\n"`

      echo "baseline_model folder: $baseline_model_folder"
  
      docker run --gpus all --rm \
          --ipc=host \
          --volume $(Build.SourcesDirectory):/ort_src \
          --volume $(Build.BinariesDirectory):/build \
          -p 8000:8000 \
          -e CCACHE_DIR=/cache -w /ort_src \
          ptebic.azurecr.io/public/aifx/acpt/stable-ubuntu2004-cu121-py310-torch222:biweekly.202410.2 /bin/bash /ort_src/docker_script_baseline.sh
    workingDirectory: $(Build.SourcesDirectory)
    displayName: "start baseline model endpoint and RAI eval in container"
    condition: eq(${{ parameters.run_baseline_model }}, 'true')


  - task: AzureCLI@2
    displayName: 'upload model to Blob Storage'
    inputs:
      azureSubscription: AIInfraBuild
      scriptLocation: inlineScript
      scriptType: bash
      inlineScript: |
        cd $(Build.BinariesDirectory)
        azcopy copy './oga_models' 'https://sunghchostorageaccount.blob.core.windows.net/test/${{ parameters.model_name }}' --recursive

